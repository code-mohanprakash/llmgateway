# LLM Gateway Environment Configuration

# Core Provider API Keys (set at least one)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# Optional Provider API Keys
GROQ_API_KEY=your_groq_api_key_here
TOGETHER_API_KEY=your_together_api_key_here
MISTRAL_API_KEY=your_mistral_api_key_here
COHERE_API_KEY=your_cohere_api_key_here
PERPLEXITY_API_KEY=your_perplexity_api_key_here
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Provider Priorities (lower number = higher priority)
OPENAI_PRIORITY=1
ANTHROPIC_PRIORITY=2
GOOGLE_PRIORITY=3
GROQ_PRIORITY=4
TOGETHER_PRIORITY=5
MISTRAL_PRIORITY=6
COHERE_PRIORITY=7
PERPLEXITY_PRIORITY=8
HUGGINGFACE_PRIORITY=9
DEEPSEEK_PRIORITY=10
OPENROUTER_PRIORITY=11

# Ollama Configuration (for local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_API_KEY=not_required_for_local

# Gateway Configuration
LOG_LEVEL=INFO

# Optional: Model Configuration Override
# MODELS_CONFIG_PATH=custom_models_config.yaml