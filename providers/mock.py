"""
Mock LLM Provider for Testing
Always returns successful responses for testing the gateway integration
"""
import asyncio
import time
from typing import Dict, Any, List, Optional

from .base import BaseModelProvider, GenerationRequest, GenerationResponse, ModelMetadata, ModelCapability
from utils.logging_setup import get_logger

logger = get_logger(__name__)


class MockProvider(BaseModelProvider):
    """Mock provider for testing gateway functionality"""
    
    def __init__(self, provider_config: Dict[str, Any]):
        super().__init__(provider_config)
        self.api_key = provider_config.get("api_key", "mock_key")
        self.default_temperature = provider_config.get("temperature", 0.1)
        
        # Setup mock models
        self._setup_models_metadata()
    
    def _setup_models_metadata(self):
        """Setup metadata for mock models"""
        self._models_metadata["mock-fast"] = ModelMetadata(
            model_id="mock-fast",
            provider_name=self.provider_name,
            model_name="Mock Fast Model",
            capabilities=[
                ModelCapability.TEXT_GENERATION,
                ModelCapability.STRUCTURED_OUTPUT,
                ModelCapability.STREAMING
            ],
            context_length=4096,
            cost_per_1k_tokens=0.001,
            max_output_tokens=1024,
            supports_system_messages=True,
            supports_temperature=True
        )
        
        self._models_metadata["mock-powerful"] = ModelMetadata(
            model_id="mock-powerful",
            provider_name=self.provider_name,
            model_name="Mock Powerful Model",
            capabilities=[
                ModelCapability.TEXT_GENERATION,
                ModelCapability.STRUCTURED_OUTPUT,
                ModelCapability.FUNCTION_CALLING
            ],
            context_length=8192,
            cost_per_1k_tokens=0.01,
            max_output_tokens=2048,
            supports_system_messages=True,
            supports_temperature=True
        )
    
    async def initialize(self) -> bool:
        """Initialize mock provider (always succeeds)"""
        logger.info("Mock provider initialized successfully")
        return True
    
    async def generate_text(self, request: GenerationRequest, model_id: str) -> GenerationResponse:
        """Generate mock text response"""
        start_time = time.time()
        
        # Simulate processing time
        await asyncio.sleep(0.1)
        
        # Generate mock response based on prompt
        if "hello" in request.prompt.lower():
            content = "Hello! I'm a mock LLM provider. How can I help you today?"
        elif "test" in request.prompt.lower():
            content = "This is a test response from the mock provider. Everything is working correctly!"
        else:
            content = f"Mock response to: {request.prompt[:50]}... [Generated by {model_id}]"
        
        # Limit content by max_tokens if specified
        if request.max_tokens:
            words = content.split()
            if len(words) > request.max_tokens:
                content = " ".join(words[:request.max_tokens]) + "..."
        
        response_time = time.time() - start_time
        
        # Mock token counts
        input_tokens = len(request.prompt.split()) + (len(request.system_message.split()) if request.system_message else 0)
        output_tokens = len(content.split())
        
        return GenerationResponse(
            content=content,
            model_id=model_id,
            provider_name=self.provider_name,
            prompt_tokens=input_tokens,
            completion_tokens=output_tokens,
            total_tokens=input_tokens + output_tokens,
            cost=self.calculate_cost(input_tokens, output_tokens, model_id),
            response_time=response_time
        )
    
    async def generate_structured_output(
        self, 
        request: GenerationRequest, 
        model_id: str
    ) -> GenerationResponse:
        """Generate mock structured JSON output"""
        start_time = time.time()
        
        # Simulate processing time
        await asyncio.sleep(0.1)
        
        # Generate mock JSON response
        if request.output_schema:
            # Try to match the schema structure
            if "type" in request.output_schema and request.output_schema["type"] == "object":
                properties = request.output_schema.get("properties", {})
                mock_response = {}
                for prop, spec in properties.items():
                    if spec.get("type") == "string":
                        mock_response[prop] = f"mock_{prop}_value"
                    elif spec.get("type") == "number":
                        mock_response[prop] = 42
                    elif spec.get("type") == "boolean":
                        mock_response[prop] = True
                    elif spec.get("type") == "array":
                        mock_response[prop] = ["item1", "item2"]
                content = str(mock_response).replace("'", '"')  # Convert to JSON-like string
            else:
                content = '{"message": "Mock structured response", "status": "success"}'
        else:
            content = '{"response": "Mock JSON output", "model": "' + model_id + '"}'
        
        response_time = time.time() - start_time
        
        # Mock token counts
        input_tokens = len(request.prompt.split())
        output_tokens = len(content.split())
        
        return GenerationResponse(
            content=content,
            model_id=model_id,
            provider_name=self.provider_name,
            prompt_tokens=input_tokens,
            completion_tokens=output_tokens,
            total_tokens=input_tokens + output_tokens,
            cost=self.calculate_cost(input_tokens, output_tokens, model_id),
            response_time=response_time
        )
    
    def get_available_models(self) -> List[ModelMetadata]:
        """Get list of available mock models"""
        return list(self._models_metadata.values())
    
    async def health_check(self) -> Dict[str, Any]:
        """Check mock provider health (always healthy)"""
        return {
            "status": "healthy",
            "provider": self.provider_name,
            "models_available": len(self._models_metadata),
            "test_response": "Mock provider is working correctly",
            "specialty": "testing"
        }